
[SYSTEM INSTRUCTION]
This is a structured knowledge file. Interpret it according to these rules:
1.  **File Structure:** Begins with a Table of Contents (TOC).
2.  **Document ID (DocID):** Each document has a short, unique `DocID` for citation.
3.  **Content Hash:** A full SHA256 hash is provided for data integrity.
4.  **Markers:** Content is encapsulated by `[START/END OF DOCUMENT]` markers.
5.  **Usage:** Use the content to answer queries, citing the `DocID` and Title.
[/SYSTEM INSTRUCTION]
---

--- TABLE OF CONTENTS ---
[DocID: GEMINI1ITCZO8ZZJ (sha256-8ca51c69ec2f5329f394aca96e72571d414dbf9ba7e902ae74ec57b327ac0b8f) | Title: Overview]
[DocID: GEMINIGLPD6Q4GV (sha256-2a99777a831f4e4804f089b5ddda1e9e9aa4f6927896174c279616c311d9bd53) | Title: Pricing.Md]
[DocID: GEMINI2B5MXY0FV9 (sha256-d55ca52c76559e28190d2b51f3c6744c52e9199d6323fdfbd2711eaca92d5af5) | Title: Prompting-Strategies.Md]
[DocID: GEMINI1VMKWHC0GW (sha256-ad84551a7e602ac695cd3dcccd536008467109e2931b91d12366e8f25e2c6441) | Title: Quickstart.Md]
[DocID: GEMINI2PC0NRH2BV (sha256-f9bcd7b0dd0b6e2fbedfa86e5e8a559ca407121cb66d982a982e967228605812) | Title: Rate-Limits.Md]
--- END OF TOC ---

[START OF DOCUMENT: GEMINI1ITCZO8ZZJ | Title: Overview]

# Gemini Developer API

[Get a Gemini API Key](https://aistudio.google.com/apikey)

Get a Gemini API key and make your first API request in minutes.

### Python

 from google import genai

 client = genai.Client()

 response = client.models.generate_content(
 model="gemini-2.5-flash",
 contents="Explain how AI works in a few words",
 )

 print(response.text)

### JavaScript

 import { GoogleGenAI } from "@google/genai";

 const ai = new GoogleGenAI({});

 async function main() {
 const response = await ai.models.generateContent({
 model: "gemini-2.5-flash",
 contents: "Explain how AI works in a few words",
 });
 console.log(response.text);
 }

 await main();

### Go

 package main

 import (
 "context"
 "fmt"
 "log"
 "google.golang.org/genai"
 )

 func main() {
 ctx := context.Background()
 client, err := genai.NewClient(ctx, nil)
 if err != nil {
 log.Fatal(err)
 }

 result, err := client.Models.GenerateContent(
 ctx,
 "gemini-2.5-flash",
 genai.Text("Explain how AI works in a few words"),
 nil,
 )
 if err != nil {
 log.Fatal(err)
 }
 fmt.Println(result.Text())
 }

### Java

 package com.example;

 import com.google.genai.Client;
 import com.google.genai.types.GenerateContentResponse;

 public class GenerateTextFromTextInput {
 public static void main(String[] args) {
 Client client = new Client();

 GenerateContentResponse response =
 client.models.generateContent(
 "gemini-2.5-flash",
 "Explain how AI works in a few words",
 null);

 System.out.println(response.text());
 }
 }

### REST

 curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent" \
 -H "x-goog-api-key: $GEMINI_API_KEY" \
 -H 'Content-Type: application/json' \
 -X POST \
 -d '{
 "contents": [
 {
 "parts": [
 {
 "text": "Explain how AI works in a few words"
 }
 ]
 }
 ]
 }'

## Meet the models

[Start building with Gemini](https://aistudio.google.com/apps)

2.5 Pro
spark

Our most powerful thinking model with features for complex reasoning and much more
[](https://ai.google.dev/gemini-api/docs/models#gemini-2.5-pro)

2.5 Flash
spark

Our most balanced model, with a 1 million token context window and more
[](https://ai.google.dev/gemini-api/docs/models/gemini#gemini-2.5-flash)

2.5 Flash-Lite
spark

Our fastest and most cost-efficient multimodal model with great performance
for high-frequency tasks
[](https://ai.google.dev/gemini-api/docs/models/gemini#gemini-2.5-flash-lite)

Veo 3
video_library

Our state of the art video generation model, with native audio
[](https://ai.google.dev/gemini-api/docs/video)

Gemini 2.5 Flash Image
imagesmode

(Nano Banana), our highly effective and precise image generation model
[](https://ai.google.dev/gemini-api/docs/image-generation)

Gemini Embeddings
data_array

Our first Gemini embedding model, designed for production RAG workflows
[](https://ai.google.dev/gemini-api/docs/embeddings)

## Explore the API

![](https://ai.google.dev/static/site-assets/images/image-generation-index.png)

### Native Image Generation (aka Nano Banana)

Generate and edit highly contextual images natively with Gemini 2.5 Flash Image.
[](https://ai.google.dev/gemini-api/docs/image-generation)
![](https://ai.google.dev/static/site-assets/images/long-context-overview.png)

### Explore long context

Input millions of tokens to Gemini models and derive understanding from unstructured images, videos, and documents.
[](https://ai.google.dev/gemini-api/docs/long-context)
![](https://ai.google.dev/static/site-assets/images/structured-outputs-index.png)

### Generate structured outputs

Constrain Gemini to respond with JSON, a structured data format suitable for automated processing.
[](https://ai.google.dev/gemini-api/docs/structured-output)

### Start building with the Gemini API

[Get started](https://ai.google.dev/gemini-api/docs/quickstart)

[END OF DOCUMENT: GEMINI1ITCZO8ZZJ]
---

[START OF DOCUMENT: GEMINIGLPD6Q4GV | Title: Pricing.Md]

<br />

<br />

Start building free of charge with generous limits, then scale up with pay-as-you-go pricing for your production ready applications.

### Free

For developers and small projects getting started with the Gemini API.

- check_circleLimited access to certain models
- check_circleFree input \& output tokens
- check_circleGoogle AI Studio access
- check_circleContent used to improve our products[\*](https://ai.google.dev/gemini-api/terms)

[Get started for Free](https://aistudio.google.com)

### Paid

For production applications that require higher volumes and advanced features.

- check_circleHigher rate limits for production deployments
- check_circleAccess to Context Caching
- check_circleBatch API (50% cost reduction)
- check_circleAccess to Google's most advanced models
- check_circleContent \*not\* used to improve our products[\*](https://ai.google.dev/gemini-api/terms)

[Upgrade to Paid](https://aistudio.google.com/api-keys)

### Enterprise

For large-scale deployments with custom needs for security, support, and compliance, powered by[Vertex AI](https://cloud.google.com/vertex-ai).

- check_circleAll features in Paid, plus optional access to:
- check_circleDedicated support channels
- check_circleAdvanced security \& compliance
- check_circleProvisioned throughput
- check_circleVolume-based discounts (based on usage)
- check_circleML Ops, Model garden and more

[Contact Sales](https://cloud.google.com/contact)

## Gemini 2.5 Pro

*`gemini-2.5-pro`*

[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-pro)

Our state-of-the-art multipurpose model, which excels at coding and complex reasoning tasks.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-----------------------------------------------|----------------------------------------------------------------------------------------------------------|
| Input price | Free of charge | $1.25, prompts \<= 200k tokens $2.50, prompts \> 200k tokens |
| Output price (including thinking tokens) | Free of charge | $10.00, prompts \<= 200k tokens $15.00, prompts \> 200k |
| Context caching price | Not available | $0.125, prompts \<= 200k tokens $0.25, prompts \> 200k $4.50 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Not available | 1,500 RPD (free), then $35 / 1,000 grounded prompts |
| Grounding with Google Maps | Not available | 10,000 RPD (free), then $25 / 1,000 grounded prompts |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-----------------------------------------------|----------------------------------------------------------------------------------------------------------|
| Input price | Not available | $0.625, prompts \<= 200k tokens $1.25, prompts \> 200k tokens |
| Output price (including thinking tokens) | Not available | $5.00, prompts \<= 200k tokens $7.50, prompts \> 200k |
| Context caching price | Not available | $0.125, prompts \<= 200k tokens $0.25, prompts \> 200k $4.50 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Not available | 1,500 RPD (free), then $35 / 1,000 grounded prompts |
| Grounding with Google Maps | Not available | Not available |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini 2.5 Flash

*`gemini-2.5-flash`*

[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash)

Our first hybrid reasoning model which supports a 1M token context window and has thinking budgets.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|------------------------------------------------------------------|---------------------------------------------------------------------------------------------|
| Input price | Free of charge | $0.30 (text / image / video) $1.00 (audio) |
| Output price (including thinking tokens) | Free of charge | $2.50 |
| Context caching price | Not available | $0.03 (text / image / video) $0.1 (audio) $1.00 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Free of charge, up to 500 RPD (limit shared with Flash-Lite RPD) | 1,500 RPD (free, limit shared with Flash-Lite RPD), then $35 / 1,000 grounded prompts |
| Grounding with Google Maps | 500 RPD | 1,500 RPD (free), then $25 / 1,000 grounded prompts |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-----------------------------------------------|---------------------------------------------------------------------------------------------|
| Input price | Not available | $0.15 (text / image / video) $0.50 (audio) |
| Output price (including thinking tokens) | Not available | $1.25 |
| Context caching price | Not available | $0.03 (text / image / video) $0.1 (audio) $1.00 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Not available | 1,500 RPD (free, limit shared with Flash-Lite RPD), then $35 / 1,000 grounded prompts |
| Grounding with Google Maps | Not available | Not available |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini 2.5 Flash Preview

*`gemini-2.5-flash-preview-09-2025`*

[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash-preview-09-2025)

The latest model based on the 2.5 Flash model. 2.5 Flash Preview is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|------------------------------------------------------------------|---------------------------------------------------------------------------------------------|
| Input price | Free of charge | $0.30 (text / image / video) $1.00 (audio) |
| Output price (including thinking tokens) | Free of charge | $2.50 |
| Context caching price | Not available | $0.03 (text / image / video) $0.1 (audio) $1.00 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Free of charge, up to 500 RPD (limit shared with Flash-Lite RPD) | 1,500 RPD (free, limit shared with Flash-Lite RPD), then $35 / 1,000 grounded prompts |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-----------------------------------------------|---------------------------------------------------------------------------------------------|
| Input price | Not available | $0.15 (text / image / video) $0.50 (audio) |
| Output price (including thinking tokens) | Not available | $1.25 |
| Context caching price | Not available | $0.03 (text / image / video) $0.1 (audio) $1.00 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Not available | 1,500 RPD (free, limit shared with Flash-Lite RPD), then $35 / 1,000 grounded prompts |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini 2.5 Flash-Lite

*`gemini-2.5-flash-lite`*

[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash-lite)

Our smallest and most cost effective model, built for at scale usage.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-------------------------------------------------------------|----------------------------------------------------------------------------------------------|
| Input price (text, image, video) | Free of charge | $0.10 (text / image / video) $0.30 (audio) |
| Output price (including thinking tokens) | Free of charge | $0.40 |
| Context caching price | Not available | $0.01 (text / image / video) $0.03 (audio) $1.00 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Free of charge, up to 500 RPD (limit shared with Flash RPD) | 1,500 RPD (free, limit shared with Flash RPD), then $35 / 1,000 grounded prompts |
| Grounding with Google Maps | 500 RPD | 1,500 RPD (free), then $25 / 1,000 grounded prompts |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-----------------------------------------------|----------------------------------------------------------------------------------------------|
| Input price (text, image, video) | Not available | $0.05 (text / image / video) $0.15 (audio) |
| Output price (including thinking tokens) | Not available | $0.20 |
| Context caching price | Not available | $0.01 (text / image / video) $0.03 (audio) $1.00 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Not available | 1,500 RPD (free, limit shared with Flash RPD), then $35 / 1,000 grounded prompts |
| Grounding with Google Maps | Not available | Not available |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini 2.5 Flash-Lite Preview

*`gemini-2.5-flash-lite-preview-09-2025`*

[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash-lite-preview-09-2025)

The latest model based on Gemini 2.5 Flash lite optimized for cost-efficiency, high throughput and high quality.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-------------------------------------------------------------|----------------------------------------------------------------------------------------------|
| Input price (text, image, video) | Free of charge | $0.10 (text / image / video) $0.30 (audio) |
| Output price (including thinking tokens) | Free of charge | $0.40 |
| Context caching price | Not available | $0.01 (text / image / video) $0.03 (audio) $1.00 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Free of charge, up to 500 RPD (limit shared with Flash RPD) | 1,500 RPD (free, limit shared with Flash RPD), then $35 / 1,000 grounded prompts |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-----------------------------------------------|----------------------------------------------------------------------------------------------|
| Input price (text, image, video) | Not available | $0.05 (text / image / video) $0.15 (audio) |
| Output price (including thinking tokens) | Not available | $0.20 |
| Context caching price | Not available | $0.01 (text / image / video) $0.03 (audio) $1.00 / 1,000,000 tokens per hour (storage price) |
| Grounding with Google Search | Not available | 1,500 RPD (free, limit shared with Flash RPD), then $35 / 1,000 grounded prompts |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini 2.5 Flash Native Audio (Live API)

*`gemini-2.5-flash-native-audio-preview-09-2025`*

[Try it in Google AI Studio](https://aistudio.google.com/app/live#gemini-2.5-flash-native-audio-preview-09-2025)

Our[Live API](https://ai.google.dev/gemini-api/docs/live)native audio models optimized for higher quality audio outputs with better pacing, voice naturalness, verbosity, and mood.

Preview models may change before becoming stable and have more restrictive rate limits.

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Free of charge | $0.50 (text) $3.00 (audio / video) |
| Output price (including thinking tokens) | Free of charge | $2.00 (text) $12.00 (audio) |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

The Live API also includes half-cascade audio generation models:

- `gemini-live-2.5-flash-preview`: Same price as the native audio model.
- `gemini-2.0-flash-live-001`: Input $0.35 (text), $2.10 (audio / image / video), Output: $1.50 (text), $8.50 (audio)

These models will be deprecated soon.

## Gemini 2.5 Flash Image

*`gemini-2.5-flash-image`*

[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash-image)

Our native image generation model, optimized for speed, flexibility, and contextual understanding. Text input and output is priced the same as[2.5 Flash](https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-flash).

Preview models may change before becoming stable and have more restrictive rate limits.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Not available | $0.30 (text / image) |
| Output price | Not available | $0.039 per image\* |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Not available | $0.15 (text / image) |
| Output price | Not available | $0.0195 per image\* |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

\[\*\] Image output is priced at $30 per 1,000,000 tokens. Output images up to 1024x1024px consume 1290 tokens and are equivalent to $0.039 per image.

## Gemini 2.5 Flash Preview TTS

*`gemini-2.5-flash-preview-tts`*

[Try it in Google AI Studio](https://aistudio.google.com/generate-speech)

Our 2.5 Flash text-to-speech audio model optimized for price-performant, low-latency, controllable speech generation.

Preview models may change before becoming stable and have more restrictive rate limits.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Free of charge | $0.50 (text) |
| Output price | Free of charge | $10.00 (audio) |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Not available | $0.25 (text) |
| Output price | Not available | $5.00 (audio) |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini 2.5 Pro Preview TTS

*`gemini-2.5-pro-preview-tts`*

[Try it in Google AI Studio](https://aistudio.google.com/generate-speech)

Our 2.5 Pro text-to-speech audio model optimized for powerful, low-latency speech generation for more natural outputs and easier to steer prompts.

Preview models may change before becoming stable and have more restrictive rate limits.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Not available | $1.00 (text) |
| Output price | Not available | $20.00 (audio) |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Not available | $0.50 (text) |
| Output price | Not available | $10.00 (audio) |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini 2.0 Flash

*`gemini-2.0-flash`*

[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.0-flash)

Our most balanced multimodal model with great performance across all tasks, with a 1 million token context window, and built for the era of Agents.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|--------------------------------------------------------------------------------|
| Input price | Free of charge | $0.10 (text / image / video) $0.70 (audio) |
| Output price | Free of charge | $0.40 |
| Context caching price | Free of charge | $0.025 / 1,000,000 tokens (text/image/video) $0.175 / 1,000,000 tokens (audio) |
| Context caching (storage) | Not available | $1.00 / 1,000,000 tokens per hour |
| Image generation pricing | Free of charge | $0.039 per image\* |
| Tuning price | Not available | Not available |
| Grounding with Google Search | Free of charge, up to 500 RPD | 1,500 RPD (free), then $35 / 1,000 grounded prompts |
| Grounding with Google Maps | 500 RPD | 1,500 RPD (free), then $25 / 1,000 grounded prompts |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|--------------------------------------------------------------------------------|
| Input price | Not available | $0.05 (text / image / video) $0.35 (audio) |
| Output price | Not available | $0.20 |
| Context caching price | Not available | $0.025 / 1,000,000 tokens (text/image/video) $0.175 / 1,000,000 tokens (audio) |
| Context caching (storage) | Not available | $1.00 / 1,000,000 tokens per hour |
| Image generation pricing | Not available | $0.0195 per image\* |
| Tuning price | Not available | Not available |
| Grounding with Google Search | Not available | 1,500 RPD (free), then $35 / 1,000 grounded prompts |
| Grounding with Google Maps | Not available | Not available |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

\[\*\] Image output is priced at $30 per 1,000,000 tokens. Output images up to 1024x1024px consume 1290 tokens and are equivalent to $0.039 per image.

## Gemini 2.0 Flash-Lite

*`gemini-2.0-flash-lite`*

[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.0-flash-lite)

Our smallest and most cost effective model, built for at scale usage.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Free of charge | $0.075 |
| Output price | Free of charge | $0.30 |
| Context caching price | Not available | Not available |
| Context caching (storage) | Not available | Not available |
| Tuning price | Not available | Not available |
| Grounding with Google Search | Not available | Not available |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Not available | $0.0375 |
| Output price | Not available | $0.15 |
| Context caching price | Not available | Not available |
| Context caching (storage) | Not available | Not available |
| Tuning price | Not available | Not available |
| Grounding with Google Search | Not available | Not available |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Imagen 4

*`imagen-4.0-generate-001`,`imagen-4.0-ultra-generate-001`,`imagen-4.0-fast-generate-001`*

[Try it in Google AI Studio](https://aistudio.google.com/generate-image)

Our latest image generation model, with significantly better text rendering and better overall image quality.

Preview models may change before becoming stable and have more restrictive rate limits.

| | Free Tier | Paid Tier, per Image in USD |
|-------------------------------|-----------------------------------------------|----------------------------------------------|
| Imagen 4 Fast image price | Not available | $0.02 |
| Imagen 4 Standard image price | Not available | $0.04 |
| Imagen 4 Ultra image price | Not available | $0.06 |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Imagen 3

*`imagen-3.0-generate-002`*

[Try it in Google AI Studio](https://aistudio.google.com/generate-image)

Our state-of-the-art image generation model, available to developers on the paid tier of the Gemini API.

| | Free Tier | Paid Tier, per Image in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Image price | Not available | $0.03 |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Veo 3.1

*`veo-3.1-generate-preview`,`veo-3.1-fast-generate-preview`*

[Try Veo 3.1](https://deepmind.google/models/veo/)

Our latest video generation model, available to developers on the paid tier of the Gemini API.

Preview models may change before becoming stable and have more restrictive rate limits.

| | Free Tier | Paid Tier, per second in USD |
|---------------------------------------------------|-----------------------------------------------|----------------------------------------------|
| Veo 3.1 Standard video with audio price (default) | Not available | $0.40 |
| Veo 3.1 Fast video with audio price (default) | Not available | $0.15 |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

**Note:** In some cases, an audio processing issue may prevent a video from being generated. You will only be charged if your video is successfully generated.

## Veo 3

*`veo-3.0-generate-001`,`veo-3.0-fast-generate-001`*

[Try Veo 3](https://deepmind.google/models/veo/)

Our stable video generation model, available to developers on the paid tier of the Gemini API.

| | Free Tier | Paid Tier, per second in USD |
|-------------------------------------------------|-----------------------------------------------|----------------------------------------------|
| Veo 3 Standard video with audio price (default) | Not available | $0.40 |
| Veo 3 Fast video with audio price (default) | Not available | $0.15 |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

**Note:** In some cases, an audio processing issue may prevent a video from being generated. You will only be charged if your video is successfully generated.

## Veo 2

*`veo-2.0-generate-001`*

[Try the API](https://ai.google.dev/gemini-api/docs/video)

Our state-of-the-art video generation model, available to developers on the paid tier of the Gemini API.

| | Free Tier | Paid Tier, per second in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Video price | Not available | $0.35 |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini Embedding

*`gemini-embedding-001`*

[Try the API](https://ai.google.dev/gemini-api/docs/embeddings)

Our newest embeddings model, more stable and with higher rate limits than previous versions, available to developers on the free and paid tiers of the Gemini API.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Free of charge | $0.15 |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Not available | $0.075 |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini Robotics-ER 1.5 Preview

*`gemini-robotics-er-1.5-preview`*

[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-robotics-er-1.5-preview)

Gemini Robotics-ER, short for Gemini Robotics-Embodied Reasoning, is a thinking model that enhances robots' abilities to understand and interact with the physical world.

### Standard

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|------------------------------------------------------------------|---------------------------------------------------------------------------------------|
| Input price | Free of charge | $0.30 (text / image / video) $1.00 (audio) |
| Output price (including thinking tokens) | Free of charge | $2.50 |
| Grounding with Google Search | Free of charge, up to 500 RPD (limit shared with Flash-Lite RPD) | 1,500 RPD (free, limit shared with Flash-Lite RPD), then $35 / 1,000 grounded prompts |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

### Batch

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Not available | Not available |
| Output price (including thinking tokens) | Not available | Not available |
| Grounding with Google Search | Not available | Not available |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemini 2.5 Computer Use Preview

*`gemini-2.5-computer-use-preview-10-2025`*

Our Computer Use model optimized for building browser control agents that automate tasks.

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|-------------------------------------------------------------|
| Input price | Not available | $1.25, prompts \<= 200k tokens $2.50, prompts \> 200k token |
| Output price | Not available | $10.00, prompts \<= 200k tokens $15.00, prompts \> 200k |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemma 3

[Try Gemma 3](https://aistudio.google.com/prompts/new_chat?model=gemma-3-27b-it)

Our lightweight, state-of the art, open model built from the same technology that powers our Gemini models.

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Free of charge | Not available |
| Output price | Free of charge | Not available |
| Context caching price | Free of charge | Not available |
| Context caching (storage) | Free of charge | Not available |
| Tuning price | Not available | Not available |
| Grounding with Google Search | Not available | Not available |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

## Gemma 3n

[Try Gemma 3n](https://aistudio.google.com/prompts/new_chat?model=gemma-3n-e4b-it)

Our open model built for efficient performance on everyday devices like mobile phones, laptops, and tablets.

| | Free Tier | Paid Tier, per 1M tokens in USD |
|------------------------------|-----------------------------------------------|----------------------------------------------|
| Input price | Free of charge | Not available |
| Output price | Free of charge | Not available |
| Context caching price | Free of charge | Not available |
| Context caching (storage) | Free of charge | Not available |
| Tuning price | Not available | Not available |
| Grounding with Google Search | Not available | Not available |
| Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms) |

\[\*\] Google AI Studio usage is free of charge in all[available regions](https://ai.google.dev/gemini-api/docs/available-regions). See[Billing FAQs](https://ai.google.dev/gemini-api/docs/billing)for details.

\[\*\*\] Prices may differ from the prices listed here and the prices offered on Vertex AI. For Vertex prices, see the[Vertex AI pricing page](https://cloud.google.com/vertex-ai/generative-ai/pricing).

\[\*\*\*\] If you are using[dynamic retrieval](https://ai.google.dev/gemini-api/docs/grounding)to optimize costs, only requests that contain at least one grounding support URL from the web in their response are charged for Grounding with Google Search. Costs for Gemini always apply. Rate limits are subject to change.

[END OF DOCUMENT: GEMINIGLPD6Q4GV]
---

[START OF DOCUMENT: GEMINI2B5MXY0FV9 | Title: Prompting-Strategies.Md]

*Prompt design* is the process of creating prompts, or natural language requests,
that elicit accurate, high quality responses from a language model.

This page introduces basic concepts, strategies, and best practices to get you
started designing prompts to get the most out of Gemini AI models.

## Topic-specific prompt guides

Looking for more specific prompt strategies? Check out our other prompting guides
on:

- [Prompting with media files](https://ai.google.dev/gemini-api/docs/files#prompt-guide)
- Prompting for image generation with [Imagen](https://ai.google.dev/gemini-api/docs/imagen#imagen-prompt-guide) and [Gemini Native Image Generation](https://ai.google.dev/gemini-api/docs/image-generation#prompt-guide)
- [Prompting for video generation](https://ai.google.dev/gemini-api/docs/video#prompt-guide)

You can find other sample prompts in the [prompt gallery](https://ai.google.dev/gemini-api/prompts)
meant to interactively showcase many of the concepts shared in this guide.

## Clear and specific instructions

An effective and efficient way to customize model behavior is to provide it with
clear and specific instructions. Instructions can be in the form of a question,
step-by-step tasks, or as complex as mapping out a user's experience and mindset.

### Input

Input is the required text in the prompt that you want the model to provide a
response to. Inputs can be a question that the model
answers (question input), a task the model performs (task input), an entity the
model operates on (entity input), or partial input that the model completes or
continues (completion input).

| **Input type** | **Prompt** | **Generated output** |
|----------------|---------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Question | What's a good name for a flower shop that specializes in selling bouquets of dried flowers? Create a list of 5 options with just the names. | Here are 10 names for a flower shop specializing in dried flowers: 1. Everlasting Blooms 2. Dried & Delightful 3. The Petal Preserve 4. Whispers of Wildflowers 5. Forever Blooms |
| Task |``` Give me a simple list of just the things that I must bring on a camping trip. The list should have 5 items. ```|``` 1. **Tent:** Your shelter from the elements. 2. **Sleeping Bag:** Stay warm and comfortable. 3. **Sleeping Pad:** Insulation and cushioning for a good night's sleep. 4. **Headlamp or Flashlight:** Light for nighttime activities. 5. **First Aid Kit:** Be prepared for minor injuries. ```|
| Entity | Classify the following items as [large, small]: Elephant Mouse Snail | Here's the classification: * **Elephant:** Large * **Mouse:** Small * **Snail:** Small |

#### Partial input completion

Generative language models work like an advanced auto completion tool. When you
provide partial content, the model can provide the rest of the content or what
it thinks is a continuation of that content as a response. When doing so, if you
include any examples or context, the model can take those examples or context
into account.

The following example provides a prompt with an instruction and an entity input:

|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**``` For the given order, return a JSON object that has the fields cheeseburger, hamburger, fries, or drink, with the value being the quantity. Order: A burger and a drink. ```**Response:**``` { "cheeseburger": 0, "hamburger": 1, "fries": 0, "drink": 1 } ```(gemini-2.5-flash) |

While the model did as prompted, writing out the instructions in natural language
can sometimes be challenging and it leaves a lot to the model's interpretation.
For example, a restaurants menu might contain many items. To reduce the size of
the JSON response, you probably want to omit the items that weren't ordered. In
this case, you can give an example and a [response prefix](https://ai.google.dev/gemini-api/docs/prompting-strategies#prefixes) and let
the model complete it:

|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**```` Valid fields are cheeseburger, hamburger, fries, and drink. Order: Give me a cheeseburger and fries Output: ```{ "cheeseburger": 1, "fries": 1 }``` Order: I want two burgers, a drink, and fries. Output: ```` **Response:**```` ```{ "hamburger": 2, "drink": 1, "fries": 1 }``` ```` (gemini-2.5-flash) |

Notice how "cheeseburger" was excluded from the output because it wasn't a part
of the order.

### Constraints

Specify any constraints on reading the prompt or generating a response. You can
tell the model what to do and not to do. For example, you can specify a constraint
in the prompt on how long you want a summary to be:

|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**``` Summarize this text in one sentence: Text: A quantum computer exploits quantum mechanical phenomena to perform calculations exponentially faster than any modern traditional computer. At very tiny scales, physical matter acts as both particles and as waves, and quantum computing uses specialized hardware to leverage this behavior. The operating principles of quantum devices is beyond the scope of classical physics. When deployed at scale, quantum computers could be used in a wide variety of applications such as: in cybersecurity to break existing encryption methods while helping researchers create new ones, in meteorology to develop better weather forecasting etc. However, the current state of the art quantum computers are still largely experimental and impractical. ```<br /> **Response:**``` Exploiting quantum mechanical phenomena, quantum computers can perform calculations exponentially faster than traditional computers for potential applications like cybersecurity and meteorology, although they are currently largely experimental and impractical. ```(gemini-2.5-flash) <br /> |

### Response format

You can give instructions that specify the format of the response. For example,
you can ask for the response to be formatted as a table, bulleted list, elevator
pitch, keywords, sentence, or paragraph. The following system instruction tells
the model to be more conversational in its response:

|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **System instruction**``` All questions should be answered comprehensively with details, unless the user requests a concise response specifically. ```**Prompt**``` What is a smart way to make a business that sells DVD's in 2025? ```**Response:**``` Starting a business selling DVDs in 2025 presents significant challenges due to the overwhelming dominance of digital streaming and on-demand services; a "smart" approach would therefore require a highly specialized niche, a strong value proposition beyond just the disc, and likely a focus on community or collector markets rather than mainstream consumption. Here's a breakdown of what a smart DVD business in 2025 would likely entail: 1. Extreme Niche Specialization: You cannot compete with streaming libraries. Your business must focus on what digital doesn't offer easily or at all. This could include: * Out-of-Print & Rare Titles: Sourcing films or TV shows that have never been released digitally or are currently unavailable on major streaming platforms. .... ```(gemini-2.5-flash) |

#### Format responses with the completion strategy

The [completion strategy](https://ai.google.dev/gemini-api/docs/prompting-strategies#completion) can also help format the response.
The following example prompts the model to create an essay outline:

|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**``` Create an outline for an essay about hummingbirds. ```**Response:**``` Here is a possible outline for an essay about hummingbirds: I. Introduction A. Hook: Start with a captivating fact or description about hummingbirds (e.g., their speed, iridescent colors, or tiny size). B. Background: Briefly introduce hummingbirds – where they are found (Americas), their reputation as unique birds. C. Thesis Statement: State the main point of the essay, which could be about the remarkable adaptations, behaviors, and ecological importance of hummingbirds. II. Appearance and Identification ..... ```(gemini-2.5-flash) |

The prompt didn't specify the format for the outline and the model chose a format
for you. To get the model to return an outline in a specific format, you can add
text that represents the start of the outline and let the model complete it based
on the pattern that you initiated.

|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**``` Create an outline for an essay about hummingbirds. I. Introduction * ```**Response:**``` Okay, here is an outline for an essay about hummingbirds, starting from the introduction you provided: I. Introduction * Hook: Start with a captivating fact or description about hummingbirds (e.g., their speed, iridescent colors, or tiny size). * Background: Briefly introduce hummingbirds – where they are found (Americas), their reputation as unique birds, and their general characteristics. * Thesis Statement: State the main point of the essay, focusing on the remarkable adaptations, behaviors, and ecological significance that make hummingbirds extraordinary. ..... ```(gemini-2.5-flash) |

## Zero-shot vs few-shot prompts

You can include examples in the prompt that show the model what getting it right
looks like. The model attempts to identify patterns and relationships from the
examples and applies them when generating a response. Prompts that contain a few
examples are called *few-shot* prompts, while prompts that provide no
examples are called *zero-shot* prompts. Few-shot prompts are often used
to regulate the formatting, phrasing, scoping, or general patterning of model
responses. Use specific and varied examples to help the model narrow its focus
and generate more accurate results.

We recommend to always include few-shot examples in your prompts. Prompts without
few-shot examples are likely to be less effective. In fact, you can remove
instructions from your prompt if your examples are clear enough in showing the
task at hand.

The following zero-shot prompt asks the model to choose the best explanation.

|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**``` Please choose the best explanation to the question: Question: How is snow formed? Explanation1: Snow is formed when water vapor in the air freezes into ice crystals in the atmosphere, which can combine and grow into snowflakes as they fall through the atmosphere and accumulate on the ground. Explanation2: Water vapor freezes into ice crystals forming snow. Answer: ```**Response:**``` Explanation1 is the better explanation because it provides more detail on the process, including how ice crystals combine and grow into snowflakes as they fall through the atmosphere. ```(gemini-2.5-flash) |

If your use case requires the model to produce concise responses, you can include
examples in the prompt that give preference to concise responses.

The following prompt provides two examples that show preference to the shorter
explanations. In the response, you can see that the examples guided the model to
choose the shorter explanation (`Explanation2`) as opposed to the longer
explanation (`Explanation1`) like it did previously.

|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**``` Below are some examples showing a question, explanation, and answer format: Question: Why is the sky blue? Explanation1: The sky appears blue because of Rayleigh scattering, which causes shorter blue wavelengths of light to be scattered more easily than longer red wavelengths, making the sky look blue. Explanation2: Due to Rayleigh scattering effect. Answer: Explanation2 Question: What is the cause of earthquakes? Explanation1: Sudden release of energy in the Earth's crust. Explanation2: Earthquakes happen when tectonic plates suddenly slip or break apart, causing a release of energy that creates seismic waves that can shake the ground and cause damage. Answer: Explanation1 Now, Answer the following question given the example formats above: Question: How is snow formed? Explanation1: Snow is formed when water vapor in the air freezes into ice crystals in the atmosphere, which can combine and grow into snowflakes as they fall through the atmosphere and accumulate on the ground. Explanation2: Water vapor freezes into ice crystals forming snow. Answer: ```**Response:**``` Answer: Explanation2 ```(gemini-2.5-flash) |

### Optimal number of examples

Models like Gemini can often pick up on patterns using a few examples, though
you may need to experiment with the number of examples to provide in the prompt
for the best results. At the same time, if you include too many examples,
the model may start to [overfit](https://developers.google.com/machine-learning/glossary#overfitting)
the response to the examples.

### Patterns vs anti patterns

Using examples to show the model a pattern to follow is more effective than using
examples to show the model an anti pattern to avoid.

⛔ **Negative pattern:**

|--------------------------------------------------------------------------------------------------------------------------|
| **Example**``` Don't end haikus with a question: Haiku are fun A short and simple poem Don't you enjoy them? ```<br /> |

✅ **Positive pattern:**

|----------------------------------------------------------------------------------------------------------------------|
| **Example**``` Always end haikus with an assertion: Haiku are fun A short and simple poem A joy to write ```<br /> |

### Consistent formatting

Make sure that the structure and formatting of few-shot examples are the same to
avoid responses with undesired formats. One of the primary objectives of adding
few-shot examples in prompts is to show the model the response format. Therefore,
it is essential to ensure a consistent format across all examples, especially
paying attention to XML tags, white spaces, newlines, and example splitters.

## Add context

You can include instructions and information in a prompt that the model needs
to solve a problem, instead of assuming that the model has all of the required
information. This contextual information helps the model understand the constraints
and details of what you're asking for it to do.

The following example asks the model to give troubleshooting guidance for a router:

|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**``` What should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and blinking slowly. ```**Response:**``` A yellow blinking light on your Google Wifi router usually indicates a problem with the internet connection. Here are some steps to troubleshoot and fix the issue: 1. Restart your router and modem: - Unplug your modem from the power outlet and wait for 30 seconds. - Plug your modem back in and wait for it to fully boot up. - Unplug your Google Wifi router and wait for 30 seconds. - Plug your Google Wifi router back in and wait for it to fully boot up. ..... ```(gemini-2.5-flash) |

The response looks like generic troubleshooting information that's not specific
to the router or the status of the LED indicator lights.

To customize the response for the specific router, you can add to the prompt the router's
troubleshooting guide as context for it to refer to when providing a response.

|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**``` Answer the question using the text below. Respond with only the text provided. Question: What should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and blinking slowly. Text: Color: Slowly pulsing yellow What it means: There is a network error. What to do: Check that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again. Color: Fast blinking yellow What it means: You are holding down the reset button and are factory resetting this device. What to do: If you keep holding down the reset button, after about 12 seconds, the light will turn solid yellow. Once it is solid yellow, let go of the factory reset button. Color: Solid yellow What it means: Router is factory resetting. What to do: This can take up to 10 minutes. When it's done, the device will reset itself and start pulsing white, letting you know it's ready for setup. Color: Solid red What it means: Something is wrong. What to do: Critical failure. Factory reset the router. If the light stays red, contact Wifi customer support. ```**Response:**``` Check that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again. ```(gemini-2.5-flash) |

## Add prefixes

A prefix is a word or phrase that you add to the prompt content that can serve
several purposes, depending on where you put the prefix:

- **Input prefix:** Adding a prefix to the input signals semantically meaningful parts of the input to the model. For example, the prefixes "English:" and "French:" demarcate two different languages.
- **Output prefix:** Even though the output is generated by the model, you can add a prefix for the output in the prompt. The output prefix gives the model information about what's expected as a response. For example, the output prefix "JSON:" signals to the model that the output should be in JSON format.
- **Example prefix:** In few-shot prompts, adding prefixes to the examples provides labels that the model can use when generating the output, which makes it easier to parse output content.

In the following example, "Text:" is the input prefix and "The answer is:" is the
output prefix.

|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Prompt:**``` Classify the text as one of the following categories. - large - small Text: Rhino The answer is: large Text: Mouse The answer is: small Text: Snail The answer is: small Text: Elephant The answer is: ```**Response:**``` The answer is: large ```(gemini-2.5-flash) |

## Break down prompts into components

For use cases that require complex prompts, you can help the model manage this
complexity by breaking things down into simpler components.

1. **Break down instructions:** Instead of having many instructions in one
 prompt, create one prompt per instruction. You can choose which prompt to
 process based on the user's input.

2. **Chain prompts:** For complex tasks that involve multiple sequential steps,
 make each step a prompt and chain the prompts together in a sequence. In this
 sequential chain of prompts, the output of one prompt in the sequence becomes
 the input of the next prompt. The output of the last prompt in the sequence
 is the final output.

3. **Aggregate responses:** Aggregation is when you want to perform different
 parallel tasks on different portions of the data and aggregate the results to
 produce the final output. For example, you can tell the model to perform one
 operation on the first part of the data, perform another operation on the rest
 of the data and aggregate the results.

## Experiment with model parameters

Each call that you send to a model includes parameter values that control how
the model generates a response. The model can generate different results for
different parameter values. Experiment with different parameter values to get
the best values for the task. The parameters available for
different models may differ. The most common parameters are the following:

1. **Max output tokens:** Specifies the maximum number of tokens that can be
 generated in the response. A token is approximately four characters. 100
 tokens correspond to roughly 60-80 words.

2. **Temperature:** The temperature controls the degree of randomness in token
 selection. The temperature is used for sampling during response generation,
 which occurs when `topP` and `topK` are applied. Lower temperatures are good
 for prompts that require a more deterministic or less open-ended response,
 while higher temperatures can lead to more diverse or creative results. A
 temperature of 0 is deterministic, meaning that the highest probability
 response is always selected.

3. **`topK`:** The `topK` parameter changes how the model selects tokens for
 output. A `topK` of 1 means the selected token is the most probable among
 all the tokens in the model's vocabulary (also called greedy decoding),
 while a `topK` of 3 means that the next token is selected from among the 3
 most probable using the temperature. For each token selection step, the
 `topK` tokens with the highest probabilities are sampled. Tokens are then
 further filtered based on `topP` with the final token selected using
 temperature sampling.

4. **`topP`:** The `topP` parameter changes how the model selects tokens for
 output. Tokens are selected from the most to least probable until the sum of
 their probabilities equals the `topP` value. For example, if tokens A, B,
 and C have a probability of 0.3, 0.2, and 0.1 and the `topP` value is 0.5,
 then the model will select either A or B as the next token by using the
 temperature and exclude C as a candidate. The default `topP` value is 0.95.

5. **`stop_sequences`:** Set a stop sequence to
 tell the model to stop generating content. A stop sequence can be any
 sequence of characters. Try to avoid using a sequence of characters that
 may appear in the generated content.

## Prompt iteration strategies

Prompt design can sometimes require a few iterations before
you consistently get the response you're looking for. This section provides
guidance on some things you can try when iterating on your prompts:

1. **Use different phrasing:** Using different words or phrasing in your prompts
 often yields different responses from the model even though they all mean the
 same thing. If you're not getting the expected results from your prompt, try
 rephrasing it.

 |----------------------------------------------------------------------------------------------------------------------------|
 |``` Version 1: How do I bake a pie? Version 2: Suggest a recipe for a pie. Version 3: What's a good pie recipe? ```<br /> |

2. **Switch to an analogous task:** If you can't get the model to follow your
 instructions for a task, try giving it instructions for an analogous task
 that achieves the same result.

 This prompt tells the model to categorize a book by using predefined categories:

 |--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
 | **Prompt:**``` Which category does The Odyssey belong to: thriller sci-fi mythology biography ```**Response:**``` The Odyssey belongs to the category of **mythology**. Here's why: * **Mythology:** The Odyssey tells the story of Odysseus, a hero from Greek mythology, and his journey home after the Trojan War. It features gods, monsters, and supernatural events common to Greek mythology. ..... ```(gemini-2.5-flash) |

 The response is correct, but the model didn't stay within the bounds of the
 options. You also want to model to just respond with one of the options instead
 of in a full sentence. In this case, you can rephrase the instructions as a
 multiple choice question and ask the model to choose an option.

 <br />

 |--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
 | **Prompt:**``` Multiple choice problem: Which of the following options describes the book The Odyssey? Options: - thriller - sci-fi - mythology - biography ```**Response:**``` The correct answer is mythology. ```(gemini-2.5-flash) |

3. **Change the order of prompt content:** The order of the content in the prompt
 can sometimes affect the response. Try changing the content order and see
 how that affects the response.

 Version 1:
 [examples]
 [context]
 [input]

 Version 2:
 [input]
 [examples]
 [context]

 Version 3:
 [examples]
 [input]
 [context]

## Fallback responses

A fallback response is a response returned by the model when either the prompt
or the response triggers a safety filter. An example of a fallback response is
"I'm not able to help with that, as I'm only a language model."

If the model responds with a fallback response, try increasing the temperature.

## Things to avoid

- Avoid relying on models to generate factual information.
- Use with care on math and logic problems.

## Generative models under the hood

This section aims to answer the question - ***Is there randomness in generative
models' responses, or are they deterministic?***

The short answer - yes to both. When you prompt a generative model, a text
response is generated in two stages. In the first stage, the generative model
processes the input prompt and generates a **probability distribution** over
possible tokens (words) that are likely to come next. For example, if you prompt
with the input text "The dog jumped over the ... ", the generative model will
produce an array of probable next words:

 [("fence", 0.77), ("ledge", 0.12), ("blanket", 0.03), ...]

This process is deterministic; a generative model will produce this same
distribution every time it's input the same prompt text.

In the second stage, the generative model converts these distributions into
actual text responses through one of several decoding strategies. A simple
decoding strategy might select the most likely token at every timestep. This
process would always be deterministic. However, you could instead choose to
generate a response by *randomly sampling* over the distribution returned by the
model. This process would be stochastic (random). Control the degree of
randomness allowed in this decoding process by setting the temperature. A
temperature of 0 means only the most likely tokens are selected, and there's no
randomness. Conversely, a high temperature injects a high degree of randomness
into the tokens selected by the model, leading to more unexpected, surprising
model responses.

## Next steps

- Now that you have a deeper understanding of prompt design, try writing your own prompts using [Google AI Studio](http://aistudio.google.com).
- To learn about multimodal prompting, see [Prompting with media files](https://ai.google.dev/gemini-api/docs/files#prompt-guide).
- To learn about image prompting, see the [Imagen prompt guide](https://ai.google.dev/gemini-api/docs/image-generation#imagen-prompt-guide)
- To learn about video prompting, see the [Veo prompt guide](https://ai.google.dev/gemini-api/docs/video#prompt-guide)

[END OF DOCUMENT: GEMINI2B5MXY0FV9]
---

[START OF DOCUMENT: GEMINI1VMKWHC0GW | Title: Quickstart.Md]

This quickstart shows you how to install our [libraries](https://ai.google.dev/gemini-api/docs/libraries) and make your first Gemini API request.

## Before you begin

You need a Gemini API key. If you don't already have one, you can [get it for free in Google AI Studio](https://aistudio.google.com/app/apikey).

## Install the Google GenAI SDK

### Python

Using [Python 3.9+](https://www.python.org/downloads/), install the
[`google-genai` package](https://pypi.org/project/google-genai/)
using the following
[pip command](https://packaging.python.org/en/latest/tutorials/installing-packages/):

 pip install -q -U google-genai

### JavaScript

Using [Node.js v18+](https://nodejs.org/en/download/package-manager),
install the
[Google Gen AI SDK for TypeScript and JavaScript](https://www.npmjs.com/package/@google/genai)
using the following
[npm command](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm):

 npm install @google/genai

### Go

Install
[google.golang.org/genai](https://pkg.go.dev/google.golang.org/genai) in
your module directory using the [go get command](https://go.dev/doc/code):

 go get google.golang.org/genai

### Java

If you're using Maven, you can install
[google-genai](https://github.com/googleapis/java-genai) by adding the
following to your dependencies:

 <dependencies>
 <dependency>
 <groupId>com.google.genai</groupId>
 <artifactId>google-genai</artifactId>
 <version>1.0.0</version>
 </dependency>
 </dependencies>

### Apps Script

1. To create a new Apps Script project, go to [script.new](https://script.google.com/u/0/home/projects/create).
2. Click **Untitled project**.
3. Rename the Apps Script project **AI Studio** and click **Rename**.
4. Set your [API key](https://developers.google.com/apps-script/guides/properties#manage_script_properties_manually)
 1. At the left, click **Project Settings** ![The icon for project settings](https://fonts.gstatic.com/s/i/short-term/release/googlesymbols/settings/default/24px.svg).
 2. Under **Script Properties** click **Add script property**.
 3. For **Property** , enter the key name: `GEMINI_API_KEY`.
 4. For **Value**, enter the value for the API key.
 5. Click **Save script properties**.
5. Replace the `Code.gs` file contents with the following code:

## Make your first request

Here is an example that uses the
[`generateContent`](https://ai.google.dev/api/generate-content#method:-models.generatecontent) method
to send a request to the Gemini API using the Gemini 2.5 Flash model.

If you [set your API key](https://ai.google.dev/gemini-api/docs/api-key#set-api-env-var) as the
environment variable `GEMINI_API_KEY`, it will be picked up automatically by the
client when using the [Gemini API libraries](https://ai.google.dev/gemini-api/docs/libraries).
Otherwise you will need to [pass your API key](https://ai.google.dev/gemini-api/docs/api-key#provide-api-key-explicitly) as
an argument when initializing the client.

Note that all code samples in the Gemini API docs assume that you have set the
environment variable `GEMINI_API_KEY`.

### Python

 from google import genai

 # The client gets the API key from the environment variable `GEMINI_API_KEY`.
 client = genai.Client()

 response = client.models.generate_content(
 model="gemini-2.5-flash", contents="Explain how AI works in a few words"
 )
 print(response.text)

### JavaScript

 import { GoogleGenAI } from "@google/genai";

 // The client gets the API key from the environment variable `GEMINI_API_KEY`.
 const ai = new GoogleGenAI({});

 async function main() {
 const response = await ai.models.generateContent({
 model: "gemini-2.5-flash",
 contents: "Explain how AI works in a few words",
 });
 console.log(response.text);
 }

 main();

### Go

 package main

 import (
 "context"
 "fmt"
 "log"
 "google.golang.org/genai"
 )

 func main() {
 ctx := context.Background()
 // The client gets the API key from the environment variable `GEMINI_API_KEY`.
 client, err := genai.NewClient(ctx, nil)
 if err != nil {
 log.Fatal(err)
 }

 result, err := client.Models.GenerateContent(
 ctx,
 "gemini-2.5-flash",
 genai.Text("Explain how AI works in a few words"),
 nil,
 )
 if err != nil {
 log.Fatal(err)
 }
 fmt.Println(result.Text())
 }

### Java

 package com.example;

 import com.google.genai.Client;
 import com.google.genai.types.GenerateContentResponse;

 public class GenerateTextFromTextInput {
 public static void main(String[] args) {
 // The client gets the API key from the environment variable `GEMINI_API_KEY`.
 Client client = new Client();

 GenerateContentResponse response =
 client.models.generateContent(
 "gemini-2.5-flash",
 "Explain how AI works in a few words",
 null);

 System.out.println(response.text());
 }
 }

### Apps Script

 // See https://developers.google.com/apps-script/guides/properties
 // for instructions on how to set the API key.
 const apiKey = PropertiesService.getScriptProperties().getProperty('GEMINI_API_KEY');
 function main() {
 const payload = {
 contents: [
 {
 parts: [
 { text: 'Explain how AI works in a few words' },
 ],
 },
 ],
 };

 const url = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent';
 const options = {
 method: 'POST',
 contentType: 'application/json',
 headers: {
 'x-goog-api-key': apiKey,
 },
 payload: JSON.stringify(payload)
 };

 const response = UrlFetchApp.fetch(url, options);
 const data = JSON.parse(response);
 const content = data['candidates'][0]['content']['parts'][0]['text'];
 console.log(content);
 }

### REST

 curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent" \
 -H "x-goog-api-key: $GEMINI_API_KEY" \
 -H 'Content-Type: application/json' \
 -X POST \
 -d '{
 "contents": [
 {
 "parts": [
 {
 "text": "Explain how AI works in a few words"
 }
 ]
 }
 ]
 }'

## What's next

Now that you made your first API request, you might want to explore the
following guides that show Gemini in action:

- [Text generation](https://ai.google.dev/gemini-api/docs/text-generation)
- [Image generation](https://ai.google.dev/gemini-api/docs/image-generation)
- [Image understanding](https://ai.google.dev/gemini-api/docs/image-understanding)
- [Thinking](https://ai.google.dev/gemini-api/docs/thinking)
- [Function calling](https://ai.google.dev/gemini-api/docs/function-calling)
- [Long context](https://ai.google.dev/gemini-api/docs/long-context)
- [Embeddings](https://ai.google.dev/gemini-api/docs/embeddings)

[END OF DOCUMENT: GEMINI1VMKWHC0GW]
---

[START OF DOCUMENT: GEMINI2PC0NRH2BV | Title: Rate-Limits.Md]

<br />

Rate limits regulate the number of requests you can make to the Gemini API within a given timeframe. These limits help maintain fair usage, protect against abuse, and help maintain system performance for all users.

[View your active rate limits in AI Studio](https://aistudio.google.com/usage?timeRange=last-28-days&tab=rate-limit)

## How rate limits work

Rate limits are usually measured across three dimensions:

- Requests per minute (**RPM**)
- Tokens per minute (input) (**TPM**)
- Requests per day (**RPD**)

Your usage is evaluated against each limit, and exceeding any of them will trigger a rate limit error. For example, if your RPM limit is 20, making 21 requests within a minute will result in an error, even if you haven't exceeded your TPM or other limits.

Rate limits are applied per project, not per API key.

Requests per day (**RPD**) quotas reset at midnight Pacific time.

Limits vary depending on the specific model being used, and some limits only apply to specific models. For example, Images per minute, or IPM, is only calculated for models capable of generating images (Imagen 3), but is conceptually similar to TPM. Other models might have a token per day limit (TPD).

Rate limits are more restricted for experimental and preview models.

## Usage tiers

Rate limits are tied to the project's usage tier. As your API usage and spending increase, you'll have an option to upgrade to a higher tier with increased rate limits.

The qualifications for Tiers 2 and 3 are based on the total cumulative spending on Google Cloud services (including, but not limited to, the Gemini API) for the billing account linked to your project.

| Tier | Qualifications |
|--------|------------------------------------------------------------------------------------------------------------|
| Free | Users in[eligible countries](https://ai.google.dev/gemini-api/docs/available-regions) |
| Tier 1 | Billing account[linked to the project](https://ai.google.dev/gemini-api/docs/billing#enable-cloud-billing) |
| Tier 2 | Total spend: \> $250 and at least 30 days since successful payment |
| Tier 3 | Total spend: \> $1,000 and at least 30 days since successful payment |

When you request an upgrade, our automated abuse protection system performs additional checks. While meeting the stated qualification criteria is generally sufficient for approval, in rare cases an upgrade request may be denied based on other factors identified during the review process.

This system helps maintain the security and integrity of the Gemini API platform for all users.

## Standard API rate limits

The following table lists the rate limits for all standard Gemini API calls.
**Note:** Any values that show`*`have no published rate limits.

### Free Tier

| Model | RPM | TPM | RPD |
| Text-out models ||||
|-------------------------------------------|-----|-----------|--------|
| Gemini 2.5 Pro | 2 | 125,000 | 50 |
| Gemini 2.5 Flash | 10 | 250,000 | 250 |
| Gemini 2.5 Flash Preview | 10 | 250,000 | 250 |
| Gemini 2.5 Flash-Lite | 15 | 250,000 | 1,000 |
| Gemini 2.5 Flash-Lite Preview | 15 | 250,000 | 1,000 |
| Gemini 2.0 Flash | 15 | 1,000,000 | 200 |
| Gemini 2.0 Flash-Lite | 30 | 1,000,000 | 200 |
| Gemini 2.5 Flash Live | \* | 1,000,000 | \* |
| Gemini 2.5 Flash Preview Native Audio | \* | 500,000 | \* |
| Gemini 2.0 Flash Live | \* | 1,000,000 | \* |
| Gemini 2.5 Flash Preview TTS | 3 | 10,000 | 15 |
| Gemini 2.0 Flash Preview Image Generation | 10 | 200,000 | 100 |
| Gemma 3 \& 3n | 30 | 15,000 | 14,400 |
| Gemini Embedding | 100 | 30,000 | 1,000 |
| Gemini Robotics-ER 1.5 Preview | 10 | 250,000 | 250 |
| Gemini 1.5 Flash (Deprecated) | 15 | 250,000 | 50 |
| Gemini 1.5 Flash-8B (Deprecated) | 15 | 250,000 | 50 |

### Tier 1

| Model | RPM | TPM | RPD | Batch Enqueued Tokens |
| Text-out models |||||
|-------------------------------------------|-------------|-----------|--------|-----------------------|
| Gemini 2.5 Pro | 150 | 2,000,000 | 10,000 | 5,000,000 |
| Gemini 2.5 Flash | 1,000 | 1,000,000 | 10,000 | 3,000,000 |
| Gemini 2.5 Flash Preview | 1,000 | 1,000,000 | 10,000 | 3,000,000 |
| Gemini 2.5 Flash-Lite | 4,000 | 4,000,000 | \* | 10,000,000 |
| Gemini 2.5 Flash-Lite Preview | 4,000 | 4,000,000 | \* | 10,000,000 |
| Gemini 2.0 Flash | 2,000 | 4,000,000 | \* | 10,000,000 |
| Gemini 2.0 Flash-Lite | 4,000 | 4,000,000 | \* | 10,000,000 |
| Gemini 2.5 Flash Live | 50 sessions | 4,000,000 | \* | \* |
| Gemini 2.5 Flash Preview Native Audio | \* | 1,000,000 | \* | \* |
| Gemini 2.0 Flash Live | 50 sessions | 4,000,000 | \* | \* |
| Gemini 2.5 Flash Preview TTS | 10 | 10,000 | 100 | \* |
| Gemini 2.5 Pro Preview TTS | 10 | 10,000 | 50 | \* |
| Gemini 2.5 Flash Image | 500 | 500,000 | 2,000 | \* |
| Gemini 2.0 Flash Preview Image Generation | 1,000 | 1,000,000 | 10,000 | \* |
| Imagen 4 Standard/Fast | 10 | \* | 70 | \* |
| Imagen 4 Ultra | 5 | \* | 30 | \* |
| Imagen 3 | 20 | \* | \* | \* |
| Veo 3.1 | 2 | \* | 10 | \* |
| Veo 3.1 Fast | 2 | \* | 10 | \* |
| Veo 3 | 2 | \* | 10 | \* |
| Veo 3 Fast | 2 | \* | 10 | \* |
| Veo 2 | 2 | \* | 50 | \* |
| Gemma 3 \& 3n | 30 | 15,000 | 14,400 | \* |
| Gemini Embedding | 3,000 | 1,000,000 | \* | \* |
| Gemini Robotics-ER 1.5 Preview | 300 | 1,000,000 | 10,000 | \* |
| Gemini 2.5 Computer Use Preview | 150 | 2,000,000 | 10,000 | \* |
| Gemini 1.5 Flash (Deprecated) | 2,000 | 4,000,000 | \* | \* |
| Gemini 1.5 Flash-8B (Deprecated) | 4,000 | 4,000,000 | \* | \* |
| Gemini 1.5 Pro (Deprecated) | 1,000 | 4,000,000 | \* | \* |

### Tier 2

| Model | RPM | TPM | RPD | Batch Enqueued Tokens |
| Text-out models |||||
|-------------------------------------------|----------------|------------|---------|-----------------------|
| Gemini 2.5 Pro | 1,000 | 5,000,000 | 50,000 | 500,000,000 |
| Gemini 2.5 Flash | 2,000 | 3,000,000 | 100,000 | 400,000,000 |
| Gemini 2.5 Flash Preview | 2,000 | 3,000,000 | 100,000 | 400,000,000 |
| Gemini 2.5 Flash-Lite | 10,000 | 10,000,000 | \* | 500,000,000 |
| Gemini 2.5 Flash-Lite Preview | 10,000 | 10,000,000 | \* | 500,000,000 |
| Gemini 2.0 Flash | 10,000 | 10,000,000 | \* | 1,000,000,000 |
| Gemini 2.0 Flash-Lite | 20,000 | 10,000,000 | \* | 1,000,000,000 |
| Gemini 2.5 Flash Live | 1,000 sessions | 10,000,000 | \* | \* |
| Gemini 2.5 Flash Preview Native Audio | \* | 10,000,000 | \* | \* |
| Gemini 2.0 Flash Live | 1,000 sessions | 10,000,000 | \* | \* |
| Gemini 2.5 Flash Preview TTS | 1,000 | 100,000 | 10,000 | \* |
| Gemini 2.5 Pro Preview TTS | 100 | 25,000 | 1,000 | \* |
| Gemini 2.5 Flash Image | 2,000 | 1,500,000 | 50,000 | \* |
| Gemini 2.0 Flash Preview Image Generation | 2,000 | 3,000,000 | 100,000 | \* |
| Imagen 4 Standard/Fast | 15 | \* | 1000 | \* |
| Imagen 4 Ultra | 10 | \* | 400 | \* |
| Imagen 3 | 20 | \* | \* | \* |
| Veo 3.1 | 4 | \* | 50 | \* |
| Veo 3.1 Fast | 4 | \* | 50 | \* |
| Veo 3 | 4 | \* | 50 | \* |
| Veo 3 Fast | 4 | \* | 50 | \* |
| Veo 2 | 2 | \* | 50 | \* |
| Gemma 3 \& 3n | 30 | 15,000 | 14,400 | \* |
| Gemini Embedding | 5,000 | 5,000,000 | \* | \* |
| Gemini Robotics-ER 1.5 Preview | 400 | 3,000,000 | 100,000 | \* |
| Gemini 2.5 Computer Use Preview | 1,000 | 5,000,000 | 50,000 | \* |
| Gemini 1.5 Flash (Deprecated) | 2,000 | 4,000,000 | \* | \* |
| Gemini 1.5 Flash-8B (Deprecated) | 4,000 | 4,000,000 | \* | \* |
| Gemini 1.5 Pro (Deprecated) | 1,000 | 4,000,000 | \* | \* |

### Tier 3

| Model | RPM | TPM | RPD | Batch Enqueued Tokens |
| Text-out models |||||
|-------------------------------------------|----------------|------------|--------|-----------------------|
| Gemini 2.5 Pro | 2,000 | 8,000,000 | \* | 1,000,000,000 |
| Gemini 2.5 Flash | 10,000 | 8,000,000 | \* | 1,000,000,000 |
| Gemini 2.5 Flash Preview | 10,000 | 8,000,000 | \* | 1,000,000,000 |
| Gemini 2.5 Flash-Lite | 30,000 | 30,000,000 | \* | 1,000,000,000 |
| Gemini 2.5 Flash-Lite Preview | 30,000 | 30,000,000 | \* | 1,000,000,000 |
| Gemini 2.0 Flash | 30,000 | 30,000,000 | \* | 5,000,000,000 |
| Gemini 2.0 Flash-Lite | 30,000 | 30,000,000 | \* | 5,000,000,000 |
| Gemini 2.5 Flash Live | 1,000 sessions | 10,000,000 | \* | \* |
| Gemini 2.5 Flash Preview Native Audio | \* | 10,000,000 | \* | \* |
| Gemini 2.0 Flash Live | 1,000 sessions | 10,000,000 | \* | \* |
| Gemini 2.5 Flash Preview TTS | 1,000 | 1,000,000 | \* | \* |
| Gemini 2.5 Pro Preview TTS | 100 | 1,000,000 | \* | \* |
| Gemini 2.5 Flash Image | 5,000 | 5,000,000 | \* | \* |
| Gemini 2.0 Flash Preview Image Generation | 5,000 | 5,000,000 | \* | \* |
| Imagen 4 Standard/Fast | 20 | \* | 15,000 | \* |
| Imagen 4 Ultra | 15 | \* | 5,000 | \* |
| Imagen 3 | 20 | \* | \* | \* |
| Veo 3.1 | 10 | \* | 500 | \* |
| Veo 3.1 Fast | 10 | \* | 500 | \* |
| Veo 3 | 10 | \* | 500 | \* |
| Veo 3 Fast | 10 | \* | 500 | \* |
| Veo 2 | 2 | \* | 50 | \* |
| Gemma 3 \& 3n | 30 | 15,000 | 14,400 | \* |
| Gemini Embedding | 10,000 | 10,000,000 | \* | \* |
| Gemini Robotics-ER 1.5 Preview | 600 | 8,000,000 | \* | \*1,000,000,000\* |
| Gemini 2.5 Computer Use Preview | 2,000 | 8,000,000 | \* | \* |
| Gemini 1.5 Flash (Deprecated) | 2,000 | 4,000,000 | \* | \* |
| Gemini 1.5 Flash-8B (Deprecated) | 4,000 | 4,000,000 | \* | \* |
| Gemini 1.5 Pro (Deprecated) | 1,000 | 4,000,000 | \* | \* |

Specified rate limits are not guaranteed and actual capacity may vary.

## Batch API rate limits

[Batch API](https://ai.google.dev/gemini-api/docs/batch-api)requests are subject to their own rate limits, separate from the non-batch API calls.

- **Concurrent batch requests:**100
- **Input file size limit:**2GB
- **File storage limit:**20GB
- **Enqueued tokens per model:** The**Batch Enqueued Tokens** column in the rate limits table lists the maximum number of tokens that can be enqueued for batch processing across all your active batch jobs for a given model. See in the[standard API rate limits table](https://ai.google.dev/gemini-api/docs/rate-limits#current-rate-limits).

## How to upgrade to the next tier

The Gemini API uses Cloud Billing for all billing services. To transition from the Free tier to a paid tier, you must first enable Cloud Billing for your Google Cloud project.

Once your project meets the specified criteria, it becomes eligible for an upgrade to the next tier. To request an upgrade, follow these steps:

- Navigate to the[API keys page](https://aistudio.google.com/app/apikey)in AI Studio.
- Locate the project you want to upgrade and click "Upgrade". The "Upgrade" option will only show up for projects that meet[next tier qualifications](https://ai.google.dev/gemini-api/docs/rate-limits#usage-tiers).

After a quick validation, the project will be upgraded to the next tier.

## Request a rate limit increase

Each model variation has an associated rate limit (requests per minute, RPM). For details on those rate limits, see[Gemini models](https://ai.google.dev/models/gemini).

[Request paid tier rate limit increase](https://forms.gle/ETzX94k8jf7iSotH9)

We offer no guarantees about increasing your rate limit, but we'll do our best to review your request.

[END OF DOCUMENT: GEMINI2PC0NRH2BV]
---

